/home/zach/kernel/cs680/net/core/dev.c[5229:5278]
  5229	/*
  5230	 * CUSTOM EDIT FOR CS680
  5231	 * Some net statistics.
  5232	 */
  5233	atomic64_t    pkt_cntr_nr_in      = ATOMIC64_INIT(0);
  5234	EXPORT_SYMBOL(pkt_cntr_nr_in);
  5235	atomic64_t    pkt_cntr_nr_merges  = ATOMIC64_INIT(0);
  5236	EXPORT_SYMBOL(pkt_cntr_nr_merges);
  5237	atomic64_t    pkt_cntr_nr_dequeue = ATOMIC64_INIT(0);
  5238	EXPORT_SYMBOL(pkt_cntr_nr_dequeue);
  5239	
  5240	static int process_backlog(struct napi_struct *napi, int quota)
  5241	{
  5242		struct softnet_data *sd = container_of(napi, struct softnet_data, backlog);
  5243		bool again = true;
  5244		int work = 0;
  5245	
  5246		/* Check if we have pending ipi, its better to send them now,
  5247		 * not waiting net_rx_action() end.
  5248		 */
  5249		if (sd_has_rps_ipi_waiting(sd)) {
  5250			local_irq_disable();
  5251			net_rps_action_and_irq_enable(sd);
  5252		}
  5253	
  5254		napi->weight = dev_rx_weight;
  5255		while (again) {
  5256			struct sk_buff *skb;
  5257	
  5258			while ((skb = __skb_dequeue(&sd->process_queue))) {
  5259	      atomic64_inc(&pkt_cntr_nr_dequeue);  /* Just dequeued a packet */
  5260				rcu_read_lock();
  5261				__netif_receive_skb(skb);
  5262				rcu_read_unlock();
  5263				input_queue_head_incr(sd);
  5264				if (++work >= quota)
  5265					return work;
  5266	
  5267			}
  5268	
  5269			local_irq_disable();
  5270			rps_lock(sd);
  5271	
  5272	    /* CUSTOM EDIT FOR CS680 */
  5273	    atomic64_add(skb_qlen(&sd->input_pkt_queue), &pkt_cntr_nr_in);
  5274	
  5275			if (skb_queue_empty(&sd->input_pkt_queue)) {
  5276				/*
  5277				 * Inline a custom version of __napi_complete().
  5278				 * only current cpu owns and manipulates this napi,
